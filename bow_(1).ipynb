{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaldaradan/data_mining/blob/main/bow_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Group P18**\n",
        "\n",
        "**Names: Sarah Kamoun (221913835) and Yalda Radan (218515080)**"
      ],
      "metadata": {
        "id": "YDpJzhI3_WjY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOWQCiK5XehY"
      },
      "source": [
        "**TO DO:**\n",
        "1. build two classifiers based on the training data using two different types of text classification approaches: Bag of Words (BOW) + text embeddings\n",
        "2. make a comparison between the two\n",
        "3. classify the reviews in the test data set and submit your prediction files (***one for each type of approach***)\n",
        "please name the file **prediction1.csv** for the method with BOW and **prediction2.csv** for the method with text embeddings. **the rows should be in the same order of examples in the test dataset.**\n",
        "\n",
        "**Notes:**\n",
        "* reviews in the training set are labeled as positive, negative, or neutral\n",
        "\n",
        "*  test set is Yelp reviews without sentiment/class labels\n",
        "\n",
        "* 60,000 reviews were randomly selected to form a training set and another 60,000 reviews were selected as testing data. Both are stored in csv files.\n",
        "\n",
        "* Each row in the training data set contain a review in text, its class label (positive, negative or neutral) and the id of the review (which you should ignore when learning a classifier).\n",
        "\n",
        "* In the test data set, each row contains the id and text of a review.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aURovF6LUjp9"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRPAnqVNYviJ",
        "outputId": "003fc415-2cc3-4f19-a09e-fe72688d4f25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# read from google drive \"train_yelp_60k.csv\" and \"test_yelp_60k.csv\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# data loading\n",
        "df_train = pd.read_csv('/content/drive/My Drive/train_yelp_60k.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/test_yelp_60k.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGCOW_WLcg0a",
        "outputId": "e76eba0e-1eaf-42c2-c560-61137bfcc006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text     Class       ID\n",
            "0  Chef Kevin Sousa's  2018 award winning restaur...  positive   727658\n",
            "1  This place has got potential. I did quite enjo...  positive  5407165\n"
          ]
        }
      ],
      "source": [
        "print(df_train.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2U6n1nzhhkd",
        "outputId": "4548fa01-f324-4f97-83e0-0b40e6087971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class\n",
            "positive    39328\n",
            "negative    14028\n",
            "neutral      6644\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# check class distribution\n",
        "print(df_train['Class'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU4cZW3Xcn3K",
        "outputId": "26624800-d12c-497f-9037-2b0b16e95e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ID                                               Text\n",
            "0   226336  All McD's these days are new and updated.  Ele...\n",
            "1  5905814  Want to try this place.  I'm so dissapointed t...\n"
          ]
        }
      ],
      "source": [
        "print(df_test.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0MMIADQeC0f"
      },
      "outputs": [],
      "source": [
        "# importing our libraries\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l34fhRNaZE7h"
      },
      "source": [
        "# BOW Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "splOJNibZ90-"
      },
      "source": [
        "* Convert the set of documents in the training data into the BOW numerical vectors.  You can use one of the two classes provided in scikit-learn to do it: CountVectorizer or TfidfVectorizer.\n",
        "\n",
        "* Select features via any feature selection methods provided in scikit-learn to do so.\n",
        "\n",
        "* Train a classifier with any of the classification methods provided in scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a8yLsGeITLU"
      },
      "outputs": [],
      "source": [
        "# Feature extraction (TfidfVectorizer)\n",
        "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1,2),stop_words='english')\n",
        "X_train = tfidf.fit_transform(df_train['Text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shfViC9eowYE",
        "outputId": "ac30a432-5a31-4113-82d1-e078ab6ee684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.775 (±0.003)\n",
            "Logistic Regression Accuracy: 0.818 (±0.003)\n",
            "Linear SVM Accuracy: 0.826 (±0.003)\n"
          ]
        }
      ],
      "source": [
        "models = {\"Naive Bayes\": MultinomialNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
        "    \"Linear SVM\": LinearSVC(),}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train, df_train['Class'], cv=5, scoring='f1_weighted')\n",
        "    print(f\"{model_name} Accuracy: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpOEw5wBtmvF",
        "outputId": "de523119-f338-4b88-c806-e517541a7519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected vocab: ['00' '000' '10' ... 'yummy' 'zero' 'zero stars']\n"
          ]
        }
      ],
      "source": [
        "# Feature selection with k = 2000\n",
        "feature_selector =  SelectKBest(chi2, k=2000)\n",
        "X_train_s = feature_selector.fit_transform(X_train, df_train['Class'])\n",
        "\n",
        "# To get selected feature names\n",
        "selected_features = feature_selector.get_support(indices=True)\n",
        "vocab = tfidf.get_feature_names_out()\n",
        "selected_vocab = vocab[selected_features]\n",
        "print(\"Selected vocab:\", selected_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHcJDIRKvpns",
        "outputId": "35cd431d-fa94-4804-9192-cb99e9452b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest Classifier...\n",
            "Cross-validation F1_macro: 0.578 (±0.004)\n"
          ]
        }
      ],
      "source": [
        "# Model training - model 1 (Random Forest)\n",
        "print(\"Training Random Forest Classifier...\")\n",
        "clf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
        "clf.fit(X_train_s, df_train['Class'])\n",
        "\n",
        "# cross-validation; we found that for sentiment analysis, F1-macro is preferable\n",
        "scores = cross_val_score(clf, X_train_s, df_train['Class'], cv=5, scoring='f1_macro')\n",
        "print(f\"Cross-validation F1_macro: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7SS2ckql66U",
        "outputId": "a67d5987-88a1-43d2-e086-af2bec3aa81d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.570 (±0.002)\n",
            "Logistic Regression Accuracy: 0.706 (±0.002)\n",
            "Linear SVM Accuracy: 0.720 (±0.003)\n"
          ]
        }
      ],
      "source": [
        "models = {\"Naive Bayes\": MultinomialNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
        "    \"Linear SVM\": LinearSVC(random_state=42, class_weight='balanced'),}\n",
        "    #clf = LinearSVC(C=1, random_state=42, class_weight='balanced')\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train_s, df_train['Class'], cv=5, scoring='f1_macro')\n",
        "    print(f\"{model_name} Accuracy: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gpo5QwM-mB83"
      },
      "outputs": [],
      "source": [
        "# Feature selection with k = 5000\n",
        "feature_selector =  SelectKBest(chi2, k=5000)\n",
        "X_train_s = feature_selector.fit_transform(X_train, df_train['Class'])\n",
        "\n",
        "# To get selected feature names\n",
        "selected_features = feature_selector.get_support(indices=True)\n",
        "vocab = tfidf.get_feature_names_out()\n",
        "selected_vocab = vocab[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8M_DbKWmGqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a338fb-f630-4af5-d795-9f15909c3172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation F1_macro: 0.569 (±0.002)\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
        "clf.fit(X_train_s, df_train['Class'])\n",
        "\n",
        "# cross-validation; we found that for sentiment analysis, F1-macro is preferable\n",
        "scores = cross_val_score(clf, X_train_s, df_train['Class'], cv=5, scoring='f1_macro')\n",
        "print(f\"Cross-validation F1_macro: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yep8ZWOHAQA3",
        "outputId": "e19708c5-d164-40c1-81a8-0c7dabfd4f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.593 (±0.004)\n",
            "Logistic Regression Accuracy: 0.714 (±0.003)\n",
            "Linear SVM Accuracy: 0.722 (±0.004)\n"
          ]
        }
      ],
      "source": [
        "models = {\"Naive Bayes\": MultinomialNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
        "    \"Linear SVM\": LinearSVC(random_state=42, class_weight='balanced'),}\n",
        "    #clf = LinearSVC(C=1, random_state=42, class_weight='balanced')\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train_s, df_train['Class'], cv=5, scoring='f1_macro')\n",
        "    print(f\"{model_name} Accuracy: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSQiSN-6Bwpz"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE()\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, df_train['Class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZY5iEjoCBZT"
      },
      "outputs": [],
      "source": [
        "# Feature selection with k = 2000\n",
        "feature_selector =  SelectKBest(chi2, k=2000)\n",
        "X_train_s = feature_selector.fit_transform(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# To get selected feature names\n",
        "selected_features = feature_selector.get_support(indices=True)\n",
        "vocab = tfidf.get_feature_names_out()\n",
        "selected_vocab = vocab[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYfIvBp2CipJ",
        "outputId": "86f39a8b-71d6-477a-8adb-ee336e6aefb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation F1_macro: 0.898 (±0.052)\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
        "\n",
        "# cross-validation; we found that for sentiment analysis, F1-macro is preferable\n",
        "scores = cross_val_score(clf, X_train_s, y_train_balanced, cv=5, scoring='f1_macro')\n",
        "print(f\"Cross-validation F1_macro: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYze1XD8CrJK",
        "outputId": "3c56f8e5-854a-46fb-9e7c-c4bf03153033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.758 (±0.012)\n",
            "Logistic Regression Accuracy: 0.820 (±0.022)\n",
            "Linear SVM Accuracy: 0.824 (±0.022)\n"
          ]
        }
      ],
      "source": [
        "models = {\"Naive Bayes\": MultinomialNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Linear SVM\": LinearSVC(random_state=42),}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train_s, y_train_balanced, cv=5, scoring='f1_macro')\n",
        "    print(f\"{model_name} Accuracy: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict test set labels\n",
        "print(\"Predicting test set labels...\")\n",
        "X_test = tfidf.transform(df_test['Text'])\n",
        "X_test_s = feature_selector.transform(X_test)\n",
        "clf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
        "clf.fit(X_train_s, y_train_balanced)\n",
        "y_pred_codes = clf.predict(X_test_s)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuRrmf77rs8w",
        "outputId": "af6f8e8d-f5ae-4944-f785-918ac7bd21bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting test set labels...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred_codes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_iisZX_yz64",
        "outputId": "7baae63a-4db8-4eff-f731-8f7f300850d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['negative' 'negative' 'positive' ... 'positive' 'positive' 'positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predictions to CSV\n",
        "df_pred = pd.DataFrame({'ID': df_test['ID'], 'Class': y_pred_codes})\n",
        "df_pred.to_csv('prediction1.csv', index=False)\n",
        "print(\"Prediction saved to 'prediction1.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhjVnJCdv8ij",
        "outputId": "8d7a0593-9afb-456b-8350-3d36689ed1d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction saved to 'prediction1.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZrZhuoqvtPm"
      },
      "source": [
        "**Random Forest with chi squared for feature selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etuT97pHZQQx",
        "outputId": "da010c86-492e-4fa4-baab-7b2fba05ff8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest Classifier...\n",
            "Cross-validation F1_macro: 0.569 (±0.002)\n",
            "Cross-validation accuracy: 0.813 (±0.002)\n",
            "Top features: ['ok' 'asked' 'delicious' 'amazing' 'best' 'rude' 'told' 'horrible'\n",
            " 'worst' 'great']\n",
            "Predicting test set labels...\n",
            "Prediction saved to 'prediction1_chi2_randomforest.csv'\n"
          ]
        }
      ],
      "source": [
        "# Feature extraction (TfidfVectorizer)\n",
        "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1,2),stop_words='english')\n",
        "X_train = tfidf.fit_transform(df_train['Text'])\n",
        "\n",
        "# Feature selection - method 1 (chi-squared)\n",
        "feature_selector =  SelectKBest(chi2, k=5000)\n",
        "X_train_s = feature_selector.fit_transform(X_train, df_train['Class'])\n",
        "\n",
        "# Model training - model 1 (Random Forest)\n",
        "print(\"Training Random Forest Classifier...\")\n",
        "clf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
        "clf.fit(X_train_s, df_train['Class'])\n",
        "\n",
        "# cross-validation; we found that for sentiment analysis, F1-macro is preferable\n",
        "scores = cross_val_score(clf, X_train_s, df_train['Class'], cv=5, scoring='f1_macro')\n",
        "print(f\"Cross-validation F1_macro: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "# cross-validation accuracy\n",
        "scores = cross_val_score(clf, X_train_s, df_train['Class'], cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation accuracy: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "# For Random Forest, top features used\n",
        "selected_features = tfidf.get_feature_names_out()[feature_selector.get_support()]\n",
        "top_features = selected_features[np.argsort(clf.feature_importances_)[-10:]]\n",
        "print(\"Top features:\", top_features)\n",
        "\n",
        "# predict test set labels\n",
        "print(\"Predicting test set labels...\")\n",
        "X_test = tfidf.transform(df_test['Text'])\n",
        "X_test_s = feature_selector.transform(X_test)\n",
        "y_pred = clf.predict(X_test_s)\n",
        "\n",
        "df_pred = pd.DataFrame({'ID': df_test['ID'],'Class': y_pred})\n",
        "df_pred.to_csv('prediction1_chi2_randomforest.csv', index=False)\n",
        "print(\"Prediction saved to 'prediction1_chi2_randomforest.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLTuG1sksg5H"
      },
      "source": [
        "**Random Forest with weights = balanced**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9913fa-3926-4468-b457-a152aa095676",
        "id": "gXd4XH1zN4XO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Random Forest Classifier with class balance...\n",
            "Cross-validation F1_macro: 0.570 (±0.004)\n",
            "Cross-validation accuracy: 0.805 (±0.002)\n",
            "Top features: ['ok' 'friendly' 'worst' 'told' 'love' 'best' 'delicious' 'amazing' 'good'\n",
            " 'great']\n",
            "Predicting test set labels...\n",
            "Prediction saved to 'prediction1_chi2_randomforest_balanced.csv'\n"
          ]
        }
      ],
      "source": [
        "# Feature extraction (TfidfVectorizer)\n",
        "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1,2),stop_words='english')\n",
        "X_train = tfidf.fit_transform(df_train['Text'])\n",
        "\n",
        "# Feature selection - method 1 (chi-squared)\n",
        "feature_selector =  SelectKBest(chi2, k=5000)\n",
        "X_train_s = feature_selector.fit_transform(X_train, df_train['Class'])\n",
        "\n",
        "# Model training - model 1 (Random Forest) with class_weight='balanced'\n",
        "print(\"Training Random Forest Classifier with class balance...\")\n",
        "clf = RandomForestClassifier(n_estimators=100,class_weight='balanced',random_state=42)\n",
        "clf.fit(X_train_s, df_train['Class'])\n",
        "\n",
        "# cross-validation; we found that for sentiment analysis, F1-macro is preferable\n",
        "scores = cross_val_score(clf, X_train_s, df_train['Class'], cv=5, scoring='f1_macro')\n",
        "print(f\"Cross-validation F1_macro: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "# cross-validation accuracy\n",
        "scores = cross_val_score(clf, X_train_s, df_train['Class'], cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation accuracy: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "# For Random Forest, top features used\n",
        "selected_features = tfidf.get_feature_names_out()[feature_selector.get_support()]\n",
        "top_features = selected_features[np.argsort(clf.feature_importances_)[-10:]]\n",
        "print(\"Top features:\", top_features)\n",
        "\n",
        "# predict test set labels\n",
        "print(\"Predicting test set labels...\")\n",
        "X_test = tfidf.transform(df_test['Text'])\n",
        "X_test_s = feature_selector.transform(X_test)\n",
        "y_pred = clf.predict(X_test_s)\n",
        "\n",
        "df_pred = pd.DataFrame({'ID': df_test['ID'],'Class': y_pred})\n",
        "df_pred.to_csv('prediction1_chi2_randomforest_balanced.csv', index=False)\n",
        "print(\"Prediction saved to 'prediction1_chi2_randomforest_balanced.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7k36hNbtB8V"
      },
      "source": [
        "**Random Forest with mutual information for feature selection (weights=balanced)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8a05c3-d258-43a3-f1b7-ed6a343698b9",
        "id": "O7I_EhzfNmIB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Random Forest Classifier with class balance...\n",
            "Cross-validation F1_macro: 0.575 (±0.005)\n",
            "Cross-validation accuracy: 0.806 (±0.002)\n",
            "Top features: ['definitely' 'friendly' 'delicious' 'love' 'told' 'best' 'worst'\n",
            " 'amazing' 'good' 'great']\n",
            "Predicting test set labels...\n",
            "Prediction saved to 'prediction1_MI_randomforest_balanced.csv'\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Feature extraction (TfidfVectorizer)\n",
        "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1,2),stop_words='english')\n",
        "X_train = tfidf.fit_transform(df_train['Text'])\n",
        "\n",
        "# Feature selection - - method 2 (mutual information)\n",
        "feature_selector =  SelectKBest(mutual_info_classif, k=5000)\n",
        "X_train_s = feature_selector.fit_transform(X_train, df_train['Class'])\n",
        "\n",
        "# Model training - model 1 (Random Forest) with class_weight='balanced'\n",
        "print(\"Training Random Forest Classifier with class balance...\")\n",
        "clf = RandomForestClassifier(n_estimators=100,class_weight='balanced',random_state=42)\n",
        "clf.fit(X_train_s, df_train['Class'])\n",
        "\n",
        "# cross-validation; we found that for sentiment analysis, F1-macro is preferable\n",
        "scores = cross_val_score(clf, X_train_s, df_train['Class'], cv=5, scoring='f1_macro')\n",
        "print(f\"Cross-validation F1_macro: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "# cross-validation accuracy\n",
        "scores = cross_val_score(clf, X_train_s, df_train['Class'], cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation accuracy: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "# For Random Forest, top features used\n",
        "selected_features = tfidf.get_feature_names_out()[feature_selector.get_support()]\n",
        "top_features = selected_features[np.argsort(clf.feature_importances_)[-10:]]\n",
        "print(\"Top features:\", top_features)\n",
        "\n",
        "# predict test set labels\n",
        "print(\"Predicting test set labels...\")\n",
        "X_test = tfidf.transform(df_test['Text'])\n",
        "X_test_s = feature_selector.transform(X_test)\n",
        "y_pred = clf.predict(X_test_s)\n",
        "\n",
        "df_pred = pd.DataFrame({'ID': df_test['ID'],'Class': y_pred})\n",
        "df_pred.to_csv('prediction1_MI_randomforest_balanced.csv', index=False)\n",
        "print(\"Prediction saved to 'prediction1_MI_randomforest_balanced.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpGBzoH5r88g"
      },
      "source": [
        "**Conclusion (Random Forest):**\n",
        "* Adding balanced weights does not seem to have improved the performance (accuracy decreased a little, f1_macro has more variability). Balanced weights should be better, logically...\n",
        "* Amongst the 2 feature selection methods, mutual information is - very slightly - better (80.5% vs. 80.6% accuracy)\n",
        "* Increasing the number of trees didn't do anything.\n",
        "* The performance is not perfect anyways, given our task (sentiment classification). Let's try a different model to see if it works better.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U39UJfRztZ2E"
      },
      "source": [
        "* As using \"mutual information\" gave slightly better results earlier, we'll start by testing it as our feature selection method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_gQzM0HtJjS"
      },
      "source": [
        "**SVM with class weighting and mutual_info to see if it's better than random forest (MI, SVM, balance)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab7e1a6-f755-4737-821c-54b72ae5a059",
        "id": "nhkznFwIPT7t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training LinearSVC Classifier with class balance...\n",
            "Cross-validation F1_macro: 0.706 (±0.006)\n",
            "Cross-validation accuracy: 0.827 (±0.005)\n",
            "Top discriminative features: ['excellent' 'perfect' 'grateful' 'best' 'awesome' 'disgusting' 'great'\n",
            " 'worst' 'amazing' 'delicious']\n",
            "Predicting test set labels...\n",
            "Prediction saved to 'prediction1_MI_svm.csv'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Feature extraction (TfidfVectorizer)\n",
        "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), stop_words='english')\n",
        "X_train = tfidf.fit_transform(df_train['Text'])\n",
        "\n",
        "# Map class labels to numerical codes\n",
        "label_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
        "y_train = df_train['Class'].map(label_map).astype(int)\n",
        "\n",
        "# Feature selection using mutual information\n",
        "feature_selector = SelectKBest(mutual_info_classif, k=5000)\n",
        "X_train_s = feature_selector.fit_transform(X_train, y_train)\n",
        "\n",
        "# Train LinearSVC for multi-class classification\n",
        "print(\"Training LinearSVC Classifier with class balance...\")\n",
        "clf = LinearSVC(C=1, random_state=42, class_weight='balanced')  # One-vs-rest by default\n",
        "clf.fit(X_train_s, y_train)\n",
        "\n",
        "# Cross-validation using F1-macro (better for imbalanced classes)\n",
        "scores = cross_val_score(clf, X_train_s, y_train, cv=5, scoring='f1_macro')\n",
        "print(f\"Cross-validation F1_macro: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "# Cross-validation accuracy\n",
        "scores = cross_val_score(clf, X_train_s, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation accuracy: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "# Inspect top discriminative features\n",
        "coef_dense = clf.coef_.toarray() if hasattr(clf.coef_, \"toarray\") else clf.coef_\n",
        "top_feature_indices = np.argsort(np.abs(coef_dense).mean(axis=0))[-10:]\n",
        "selected_features = tfidf.get_feature_names_out()[feature_selector.get_support()]\n",
        "print(\"Top discriminative features:\", selected_features[top_feature_indices])\n",
        "\n",
        "# Predict test set labels\n",
        "print(\"Predicting test set labels...\")\n",
        "X_test = tfidf.transform(df_test['Text'])\n",
        "X_test_s = feature_selector.transform(X_test)\n",
        "y_pred_codes = clf.predict(X_test_s)\n",
        "\n",
        "# Map numerical predictions back to class labels\n",
        "y_pred_cat = {1: 'positive', 0: 'neutral', -1: 'negative'}\n",
        "y_pred = [y_pred_cat[code] for code in y_pred_codes]\n",
        "\n",
        "# Save predictions to CSV\n",
        "df_pred = pd.DataFrame({'ID': df_test['ID'], 'Class': y_pred})\n",
        "df_pred.to_csv('prediction1_MI_svm.csv', index=False)\n",
        "print(\"Prediction saved to 'prediction1_MI_svm.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKG0SADnuLEr"
      },
      "source": [
        "**Notes**\n",
        "* The f1_macro improved from being around 57% to 70% when using SVM instead of random forest, and accuracy improved from 80% to 82.7% so we're headed in a good direction for our task.\n",
        "* Our next idea is to expand the n_gram range to include longer expressions ('not the best' for example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiomShGm3Aqe"
      },
      "source": [
        "**SVM + expanding the ngram_range to include 3-word phrases**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xizH-pfhqp55",
        "outputId": "9a7ee62c-32d0-4b0b-e150-016cf05c71cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LinearSVC Classifier with class balance...\n",
            "Cross-validation F1_macro: 0.707 (±0.007)\n",
            "Cross-validation accuracy: 0.827 (±0.005)\n",
            "Top discriminative features: ['excellent' 'perfect' 'grateful' 'best' 'awesome' 'disgusting' 'great'\n",
            " 'worst' 'amazing' 'delicious']\n",
            "Predicting test set labels...\n",
            "Prediction saved to 'prediction1_MI3_svm.csv'\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Feature extraction (TfidfVectorizer) with ngram 3 this time\n",
        "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 3), stop_words='english')\n",
        "X_train = tfidf.fit_transform(df_train['Text'])\n",
        "\n",
        "# Map class labels to numerical codes\n",
        "label_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
        "y_train = df_train['Class'].map(label_map).astype(int)\n",
        "\n",
        "# Feature selection using mutual information\n",
        "feature_selector = SelectKBest(mutual_info_classif, k=5000)\n",
        "X_train_s = feature_selector.fit_transform(X_train, y_train)\n",
        "\n",
        "# Train LinearSVC for multi-class classification\n",
        "print(\"Training LinearSVC Classifier with class balance...\")\n",
        "clf = LinearSVC(C=1, random_state=42, class_weight='balanced')  # One-vs-rest by default\n",
        "clf.fit(X_train_s, y_train)\n",
        "\n",
        "# Cross-validation using F1-macro (better for imbalanced classes)\n",
        "scores = cross_val_score(clf, X_train_s, y_train, cv=5, scoring='f1_macro')\n",
        "print(f\"Cross-validation F1_macro: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "# Cross-validation accuracy\n",
        "scores = cross_val_score(clf, X_train_s, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation accuracy: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "# Inspect top discriminative features\n",
        "coef_dense = clf.coef_.toarray() if hasattr(clf.coef_, \"toarray\") else clf.coef_\n",
        "top_feature_indices = np.argsort(np.abs(coef_dense).mean(axis=0))[-10:]\n",
        "selected_features = tfidf.get_feature_names_out()[feature_selector.get_support()]\n",
        "print(\"Top discriminative features:\", selected_features[top_feature_indices])\n",
        "\n",
        "# Predict test set labels\n",
        "print(\"Predicting test set labels...\")\n",
        "X_test = tfidf.transform(df_test['Text'])\n",
        "X_test_s = feature_selector.transform(X_test)\n",
        "y_pred_codes = clf.predict(X_test_s)\n",
        "\n",
        "# Map numerical predictions back to class labels\n",
        "y_pred_cat = {1: 'positive', 0: 'neutral', -1: 'negative'}\n",
        "y_pred = [y_pred_cat[code] for code in y_pred_codes]\n",
        "\n",
        "# Save predictions to CSV\n",
        "df_pred = pd.DataFrame({'ID': df_test['ID'], 'Class': y_pred})\n",
        "df_pred.to_csv('prediction1_MI3_svm.csv', index=False)\n",
        "print(\"Prediction saved to 'prediction1_MI3_svm.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLgtkgYOu80y"
      },
      "source": [
        "**Notes**\n",
        "* No change in performance, but let's try expanding the range to 5 to see if this could help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbugJTC2YiUU"
      },
      "source": [
        "**Trying to increase ngram to 5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0058454a-1a76-47ef-a456-3a0fa3c53dcb",
        "id": "xEty9xIIPv0q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training LinearSVC Classifier with class balance...\n",
            "Cross-validation F1_macro: 0.707 (±0.007)\n",
            "Cross-validation accuracy: 0.827 (±0.005)\n",
            "Top discriminative features: ['excellent' 'perfect' 'grateful' 'best' 'awesome' 'disgusting' 'great'\n",
            " 'worst' 'amazing' 'delicious']\n",
            "Predicting test set labels...\n",
            "Prediction saved to 'prediction1_MI5_svm.csv'\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Feature extraction (TfidfVectorizer) with ngram 5 this time\n",
        "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 5), stop_words='english')\n",
        "X_train = tfidf.fit_transform(df_train['Text'])\n",
        "\n",
        "# Map class labels to numerical codes\n",
        "label_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
        "y_train = df_train['Class'].map(label_map).astype(int)\n",
        "\n",
        "# Feature selection using mutual information\n",
        "feature_selector = SelectKBest(mutual_info_classif, k=5000)\n",
        "X_train_s = feature_selector.fit_transform(X_train, y_train)\n",
        "\n",
        "# Train LinearSVC for multi-class classification\n",
        "print(\"Training LinearSVC Classifier with class balance...\")\n",
        "clf = LinearSVC(C=1, random_state=42, class_weight='balanced')  # One-vs-rest by default\n",
        "clf.fit(X_train_s, y_train)\n",
        "\n",
        "# Cross-validation using F1-macro (better for imbalanced classes)\n",
        "scores = cross_val_score(clf, X_train_s, y_train, cv=5, scoring='f1_macro')\n",
        "print(f\"Cross-validation F1_macro: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "# Cross-validation accuracy\n",
        "scores = cross_val_score(clf, X_train_s, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation accuracy: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "# Inspect top discriminative features\n",
        "coef_dense = clf.coef_.toarray() if hasattr(clf.coef_, \"toarray\") else clf.coef_\n",
        "top_feature_indices = np.argsort(np.abs(coef_dense).mean(axis=0))[-10:]\n",
        "selected_features = tfidf.get_feature_names_out()[feature_selector.get_support()]\n",
        "print(\"Top discriminative features:\", selected_features[top_feature_indices])\n",
        "\n",
        "# Predict test set labels\n",
        "print(\"Predicting test set labels...\")\n",
        "X_test = tfidf.transform(df_test['Text'])\n",
        "X_test_s = feature_selector.transform(X_test)\n",
        "y_pred_codes = clf.predict(X_test_s)\n",
        "\n",
        "# Map numerical predictions back to class labels\n",
        "y_pred_cat = {1: 'positive', 0: 'neutral', -1: 'negative'}\n",
        "y_pred = [y_pred_cat[code] for code in y_pred_codes]\n",
        "\n",
        "# Save predictions to CSV\n",
        "df_pred = pd.DataFrame({'ID': df_test['ID'], 'Class': y_pred})\n",
        "df_pred.to_csv('prediction1_MI5_svm.csv', index=False)\n",
        "print(\"Prediction saved to 'prediction1_MI5_svm.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph51UahwZG4C"
      },
      "source": [
        "**Notes**\n",
        "* It's not getting better with more ngram range. Let's revert to (1,3) and see if changing the hyperparameter \"C\" of the SVM changes anything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uWjmEq84p8p"
      },
      "source": [
        "**reducing C to 0.05 and n_gram back to (1,2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8UxT4wy5AsM",
        "outputId": "4651306b-9672-4de4-8bee-2334e59b7b81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LinearSVC Classifier with class balance...\n",
            "Cross-validation F1_macro: 0.715 (±0.004)\n",
            "Cross-validation accuracy: 0.839 (±0.003)\n",
            "Top discriminative features: ['horrible' 'excellent' 'love' 'awesome' 'ok' 'best' 'worst' 'amazing'\n",
            " 'delicious' 'great']\n",
            "Predicting test set labels...\n",
            "Prediction saved to 'prediction1_MI2_C005_svm.csv'\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Feature extraction (TfidfVectorizer) with ngram 2 this time\n",
        "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), stop_words='english')\n",
        "X_train = tfidf.fit_transform(df_train['Text'])\n",
        "\n",
        "# Map class labels to numerical codes\n",
        "label_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
        "y_train = df_train['Class'].map(label_map).astype(int)\n",
        "\n",
        "# Feature selection using mutual information\n",
        "feature_selector = SelectKBest(mutual_info_classif, k=5000)\n",
        "X_train_s = feature_selector.fit_transform(X_train, y_train)\n",
        "\n",
        "# Train LinearSVC for multi-class classification\n",
        "print(\"Training LinearSVC Classifier with class balance...\")\n",
        "clf = LinearSVC(C=0.05, random_state=42, class_weight='balanced')  # One-vs-rest by default\n",
        "clf.fit(X_train_s, y_train)\n",
        "\n",
        "# Cross-validation using F1-macro (better for imbalanced classes)\n",
        "scores = cross_val_score(clf, X_train_s, y_train, cv=5, scoring='f1_macro')\n",
        "print(f\"Cross-validation F1_macro: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "# Cross-validation accuracy\n",
        "scores = cross_val_score(clf, X_train_s, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation accuracy: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "# Inspect top discriminative features\n",
        "coef_dense = clf.coef_.toarray() if hasattr(clf.coef_, \"toarray\") else clf.coef_\n",
        "top_feature_indices = np.argsort(np.abs(coef_dense).mean(axis=0))[-10:]\n",
        "selected_features = tfidf.get_feature_names_out()[feature_selector.get_support()]\n",
        "print(\"Top discriminative features:\", selected_features[top_feature_indices])\n",
        "\n",
        "# Predict test set labels\n",
        "print(\"Predicting test set labels...\")\n",
        "X_test = tfidf.transform(df_test['Text'])\n",
        "X_test_s = feature_selector.transform(X_test)\n",
        "y_pred_codes = clf.predict(X_test_s)\n",
        "\n",
        "# Map numerical predictions back to class labels\n",
        "y_pred_cat = {1: 'positive', 0: 'neutral', -1: 'negative'}\n",
        "y_pred = [y_pred_cat[code] for code in y_pred_codes]\n",
        "\n",
        "# Save predictions to CSV\n",
        "df_pred = pd.DataFrame({'ID': df_test['ID'], 'Class': y_pred})\n",
        "df_pred.to_csv('prediction1_MI2_C005_svm', index=False)\n",
        "print(\"Prediction saved to 'prediction1_MI2_C005_svm.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Final experiment"
      ],
      "metadata": {
        "id": "Sg715tT-rAJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Feature extraction (TfidfVectorizer) with ngram 2 this time\n",
        "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), stop_words='english')\n",
        "X_train = tfidf.fit_transform(df_train['Text'])\n",
        "\n",
        "# Map class labels to numerical codes\n",
        "label_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
        "y_train = df_train['Class'].map(label_map).astype(int)\n",
        "\n",
        "smote = SMOTE()\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Feature selection with k = 2000\n",
        "feature_selector =  SelectKBest(chi2, k=2000)\n",
        "X_train_s = feature_selector.fit_transform(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Train LinearSVC for multi-class classification\n",
        "print(\"Training LinearSVC Classifier with class balance...\")\n",
        "clf = LinearSVC(C=0.05, random_state=42, class_weight='balanced')  # One-vs-rest by default\n",
        "clf.fit(X_train_s, y_train_balanced)\n",
        "\n",
        "# Cross-validation using F1-macro (better for imbalanced classes)\n",
        "scores = cross_val_score(clf, X_train_s, y_train_balanced, cv=5, scoring='f1_macro')\n",
        "print(f\"Cross-validation F1_macro: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "# Cross-validation accuracy\n",
        "scores = cross_val_score(clf, X_train_s, y_train_balanced, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation accuracy: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "# Predict test set labels\n",
        "print(\"Predicting test set labels...\")\n",
        "X_test = tfidf.transform(df_test['Text'])\n",
        "X_test_s = feature_selector.transform(X_test)\n",
        "y_pred_codes = clf.predict(X_test_s)\n",
        "\n",
        "# Map numerical predictions back to class labels\n",
        "y_pred_cat = {1: 'positive', 0: 'neutral', -1: 'negative'}\n",
        "y_pred = [y_pred_cat[code] for code in y_pred_codes]\n",
        "\n",
        "# Save predictions to CSV\n",
        "df_pred = pd.DataFrame({'ID': df_test['ID'], 'Class': y_pred})\n",
        "df_pred.to_csv('prediction1_lasttest.csv', index=False)\n",
        "print(\"Prediction saved to 'prediction1_lasttest.csv'\")"
      ],
      "metadata": {
        "id": "XOtYnCYnnjWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195e83a2-a99c-40c5-ba18-51b7ac62051b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LinearSVC Classifier with class balance...\n",
            "Cross-validation F1_macro: 0.803 (±0.019)\n",
            "Cross-validation accuracy: 0.803 (±0.019)\n",
            "Predicting test set labels...\n",
            "Prediction saved to 'prediction1_lasttest.csv'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}